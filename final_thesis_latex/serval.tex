\newpage
\section{The Serval Networking Architecture}
\subsection{Introduction}
Serval\footnote{More information about the Serval Architecture can be found in the presentation in the Appendix (\ref{sec:servaldhtpres}).} is an end-host stack evolving into a service-centric network architecture, proposed and prototyped by the \href{https://sns.cs.princeton.edu/}{systems and networking group} at \href{https://www.princeton.edu}{Princeton University}, in 2012.

\paragraph{} In the original paper "A Service Access Layer, at Your Service" (2011)\cite{Freedman2011} and later on "Serval: An End-Host Stack for Service-Centric Networking" (2012)\cite{Nordstrom2012}, Freedman, Nordstr{\"o}m et. al. first decompose the needs of modern networked applications, locate the discordances with the current Network Stack, study previous work and how each of them individually fails to stand as a proper solution, rethink the current TCP/IP Networking Stack and propose two simple abstractions that can obliterate the legacy problems discussed on Problem Definition (\ref{problemdefinition}).\\
\indent Furthermore they investigate how those abstractions fit in a new 3.5 layer, the Service Access Layer (SAL)\nomenclature{SAL}{Service Access Layer}, and emphasize on the clean service-level data/control plane separation it imposes.
Additionally, they review a formally-verified end-to-end connection control protocol (ECCP) \nomenclature{ECCP}{End-to-End Connection Control Protocol} [TODO], which elevates services to first-class citizens.
After all, they focus on the SAL prototype and the lessons learned from building it.

\subsection{Proposed abstractions}
As will be discussed later on at the section "Review of Relative Bibliography" (\ref{sec:reviewbibliography}), various abstractions have been proposed in order to support the concept of Service-Centric networking.
Deciding the right abstractions premises first the detailed understanding of where a problem resides, and then the genuine intuition for conceiving the simple yet powerful generalizations that better conform with the current and future needs.
Those abstractions should be transparent enough for legacy ports and hot swapping with the prevalent systems, in the meantime powerful to break ground for future advancements.\\
\indent We appraise the Serval abstractions of \emph{Service Names} and \emph{Flow Identifiers} for being a great solution on the overloading of identifiers within and across the present TCP/IP stack.
Also, for the tight fit of those abstractions in the separation of data and control plane.
Finally, it is remarkable how the adoption of those abstractions requires minimal if no modifications at all in the infrastructure that powers networks today.

\subsubsection{Service Names}
The main idea behind Service-Centric Networking is that nowadays network users request services by their names and are completely agnostic of the underlying procedures.
Hereby an abstraction is needed for identifying a service, resolving and of course effectively routing a request to an instance of that service, according to specific rules.
For that reason Serval introduces service names, or \emph{serviceIDs}.\\
\indent ServiceIDs are large (256 bit long) strings, that correspond to a service, or a group of services.
Part of Serval packets as a Service Access Extension header in the synchronization process (SYN and SYN-ACK flags in ECCP state machine figure \ref{fig:ECCP_st}), serviceIDs assist in resolution and service-level routing.
Furthermore they are used as persistent, global identifiers for easier handling of replicated services, virtual machine migrations or mobile hosts, when there is a need for end-point signaling.\\
\indent What is unique about Serval's adifferencebstraction of service identifiers is that since they are managed by the SAL, they are positioned below the transport layer.
Jointly with Serval active sockets, the abstraction of service names obscures host identifiers (IP and Port) from the application layer, but stills offers powerful, familiar APIs\nomenclature{API}{Application Programming Interface} to networked application developers.
\indent service granularity (block allocation) \\
\indent To sum up, in an elegant way serviceIDs promote services to the principal entities in the network, by giving applications intermediate access to the service control plane and a
And it manages to do so while hiding unneeded abstractions, such as the $<IP, port>$ tuple.

\subsubsection{End-host flow identifiers}
The other problem Serval is intending to counteract, is the 

\subsection{Service Resolution}
Those service names in a deeper level get mapped to 
human readable strings similar to domain names, for identifying services.
regardless it's geographical position, the port it is bound, 

\subsubsection{Hierarchical Resolution}
Relative to today's domain name system, those serviceIDs can be mapped to human-readable strings, much like URIs.

\subsubsection{Flat Resolution Schemes}
Another approach suggests that serviceIDs are calculated by a hash function on a service prefix and an application-level instance unique key.
This practice of a \emph{semantic-free, flat} namespace better supports networks without a hierarchical structure, like datacenter and Wide Area networks.
By semantic-free\cite{Walfisha2004} reference we mean that by default 

\subsection{Service-Level Routing} 
No need for deep packet inspection in load balancers


\subsubsection{Late binding}

\subsection{Serval Network Stack}
Extra points go to Serval for being transport-protocol agnostic.
This means that developers may choose to use either TCP, UDP\nomenclature{UDP}{User Datagram Protocol}, ATP\nomenclature{ATP}{AppleTalk Transaction Protocol}, FCP\nomenclature{FCP}{Fibre Channel Protocol} or actually any transport protocol, since it is supported by SAL, without modifying the source code of their application.
This opens new windows for experimentation and innovation.

\subsubsection{Service Controller}

\subsubsection{Service Access Layer}
extremes
\subsubsection{Serval Packets Structure}

\input{ports.tex}

\subsection{Profiling the Serval prototype implementation}
Among the admirable headliners of Serval is the working prototype version of the proposed architecture.
In more than 28000 lines of code\footnote{Serval is an Open Source project, hosted at a public repository\\ \url{https://github.com/princeton-sns/serval/}.} covering functionality of the Service Access Layer (both in userlevel operation and as a Linux kernel module), bindings for multiple programming languages, a translator, libraries and examples for writing Serval compatible applications, and with a reported throughput comparable to the unmodified TCP/IP stack, it is clearly showcased the feasibility of the solution.
\\ \indent In this section we are profiling the prototype in regard to the following parameters:
\begin{enumerate}
  \item CPU Instructions and Cycles
  \item System Call execution times
  \item Execution time needed for the completion of a numbered iteration of requests
  \item Number of packers per request, bytes on the wire
\end{enumerate}
Then we will be presenting the results juxtaposed to the measurements of the unchanged TCP/IP stack and the AF\_INET family.

\paragraph{} Output was obtained on a HP Prodesk 600 G1 --Intel(R) Core(TM) i5-4570 @ 3.20GHZ, 4GB RAM-- machine running Ubuntu 11.04 (Natty Narwahl) kernel version 2.6.38-16-generic (rebuilt with debug symbols).
\\ \indent The profiling tools we used include gprof, perf, oprofile, valgrind, strace, zoom and google performance tools.
For the tests with gprof, valgrind, oprofile and strace, Serval module and http\_client were built with debug symbols.
Extra, for gprof testing, Serval was built with CFLAGS, LDFLAGS and CPPFLAGS equal to "-pg".
\\ \indent For the measurements we ported libmicrohttpd to use Serval active sockets.
Also, we implemented a simple HTTP client which supports both AF\_INET and the AF\_SERVAL socket families, depending on the options passed during the call.
For each case, we used the INET and Serval version of librehttpd and http\_client respectively.
Therefore, besides the connectivity parts, both INET and SERVAL versions are working with the same logic in creating, exchanging and processing requests.
This way we believe the tests can give unbiased results, which would not be the case if for example we used apache for INET and libmicrohttpd for SERVAL requests.
\\ \indent Source code of libmicrohttpd and http\_client, along with the integration of Serval patch in the build procedure of nginx, can be found in the Appendix (\ref{sec:appendix}).
Benchmark results are published in the ServalDHT repository \footnote{\url{https://github.com/misaakidis/ServalDHT}}.

\paragraph{Serval's performance in the worst case scenario} \hfill \\
In a network architecture benchmarking what matters the most is its total throughput under a stress test.
In other words, the data rate of information (both headers and payload) and the number of packets that can be processed during a specific time frame.
An excellent tool for this case, \emph{iperf}, proved Serval's TCP throughput to be very close to the original TCP's one, almost fully utilizing a GigE interface. \nomenclature{GigE}{Gigabit Ethernet}
The authors explain that the existing small difference is due to missing optimizations in Serval's prototype.
\\ \indent We are examining Serval from a completely different perspective.
We dive into the implementation of SAL and serval.ko module and the overhead in using the Serval APIs.
And we do so in the worst possible scenario for an architecture that is establishing its own identifiers in the end host stacks.
\\ \indent It is SAL's responsibility to create the flows and synchronize the sockets in either side \footnote{Specifically for TCP, Serval is using the functionality that corresponds only to the ESTABLISHED state.}.
This means that when binding an active socket to a serviceID, the SAL must insert an entry into the flow table, register the service in the service table with a DEMUX rule and propagate the service registration to the network (may it be an anycast flood or a request to a singe service router).
Also, when connecting to a service, SAL must first convert a service name to a serviceID, resolve the serviceID, and finally establish a connection using CONTROL and SERVICE headers.
Correspondingly, closing a connection requires the exchange of packets with CONTROL headers.
In both cases, must-have checks like whether a serviceID is of an appropriate format, are more computational effort to the perquisite ones.
\\ \indent Once a connection has been established, the only significant overhead is the addition of a 12 bytes Serval header with the source and destination flowIDs, and the demultiplexing of incoming packets.
We can presume for those reasons, that Serval (and any other relative architecture) is struggling during the process of establishing a connection.
\\ \indent The case scenario we are testing is consisted of a client that connects to a service and requests information that can fit within a single response packet.
Since both the server and the client are running in the same machine, we can presume that the available bandwidth exempts network "links" from being responsible for a bottleneck.
The results show how well the Serval implementation can manage when it is pushed to the limit.

\paragraph{Instructions and CPU Cycles} \hfill \\
\begin{table}
\begin{center}
  \begin{tabular}{l||cc|cc}
  	\toprule
  	Metric			&	\multicolumn{2}{c}{PF\_INET}	&	\multicolumn{2}{c}{PF\_SERVAL}	\\
  	\midrule
    Instructions	&	690,559		&	$\pm$0.009\%	&	1,864,287	&	$\pm$0.054\%	\\
    CPU Cycles		&	1,019,096	&	$\pm$0.062\%	&	8,799,912	&	$\pm$0.191\%	\\
    \bottomrule
  \end{tabular}
  \caption[Benchmark: Instructions and CPU Cycles]{Instructions count and CPU Cycles in 10000 runs of http\_client}
\end{center}
\end{table}

\paragraph{System Calls execution times} \hfill \\
\begin{table}
\begin{center}
  \begin{tabular}{l||c|c}
  	\toprule
  	Syscall			&	PF\_INET	&	PF\_SERVAL	\\
  	\midrule
    socket			&	0.145		&	0.070		\\
    setsockopt		&	0.160		&	0.118		\\
    connect			&	0.117		&	0.113		\\
    getsockname		&	0.300		&	0.552		\\
    send			&	0.089		&	0.086		\\
    recv			&	0.159		&	0.313		\\
    close			&	0.086		&	0.087		\\
    \bottomrule
  \end{tabular}
  \caption[Benchmark: System Call execution times]{Kernel System Calls execution times (in milliseconds)}
\end{center}
\end{table}

\paragraph{Finite Requests loop timing} \hfill \\
\begin{table}
\begin{center}
  \begin{tabular}{l||cc|cc|c}
  	\toprule
  	Requests	&	\multicolumn{2}{c}{PF\_INET}	&	\multicolumn{2}{c}{PF\_SERVAL}	&	Increase	\\
  	\midrule
    10			&	1.171		&	$\pm$2.171\%	&	1.845		&	$\pm$1.542\%	&	57.5\%		\\
    100			&	0.399		&	$\pm$7.248\%	&	0.686		&	$\pm$9.404\%	&	71.9\%		\\
    1000		&	0.590		&	$\pm$5.835\%	&	0.837		&	$\pm$7.751\%	&	41.9\%		\\
    \bottomrule
  \end{tabular}
  \caption[Benchmark: Requests execution times]{Requests execution times}
\end{center}
\end{table}


\paragraph{Packets specific metrics} \hfill \\
\paragraph{System Calls execution times} \hfill \\
\begin{table}
\begin{center}
  \begin{tabular}{l||c|c}
  	\toprule
  	Metric				&	PF\_INET	&	PF\_SERVAL	\\
  	\midrule
    Packets/request		&	10			&	15			\\
    Bytes/request		&	922			&	1392		\\
    \bottomrule
  \end{tabular}
  \caption[Benchmark: Packets and bytes exchanged per request]{Packets and bytes exchanged per request}
\end{center}
\end{table}